# RF-based Token Compression Configuration

experiment:
  name: "rf_vision_token_compression"
  seed: 42
  use_wandb: true
  wandb_project: "rf-vision-token-compression"
  wandb_entity: medicalissues  # Set your wandb entity here

# Model settings
model:
  clip:
    model_name: "openai/clip-vit-large-patch14" #-336
    freeze: true
    image_size: 224 #336

  compressor:
    hidden_dim: 1024  # CLIP ViT-L token dimension

  rf_discriminator:
    # Fixed architecture: 1024 -> 512 -> 256 -> 1
    # Processes single tokens (B*N, 1024) where N = output_grid_size^2
    dropout: 0.1

# Loss settings
loss:
  rf_wgan:
    lambda_gp: 10.0  # Gradient penalty weight

  rf_cosine_similarity:
    # Loss = 1 - mean_similarity (range: 0 to 2)
    # No additional parameters needed

  weights:
    wgan: 1.0      # Weight for WGAN-GP loss
    cosine: 1.0    # Weight for Cosine Similarity loss

# Training settings
training:
  epochs: 100
  batch_size: 256
  learning_rate: 1e-4
  discriminator_lr: 1e-4
  n_critic: 1  # Number of discriminator updates per generator update (1:1 for speed)

  # Optimizer settings
  optimizer:
    betas: [0.5, 0.999]
    weight_decay: 0.0

  # Learning rate scheduler (optional)
  scheduler:
    use: false
    type: "cosine"
    warmup_epochs: 3
    min_lr: 1e-6

# Compression settings - Choose one of 4 supported configurations:
# 1. 24 → 12: kernel=3, stride=2, RF=3×3 (9.59M params)
# 2. 24 → 8:  kernel=5, stride=3, RF=5×5 (26.28M params)
# 3. 16 → 12: kernel=5, stride=1, RF=5×5 (26.36M params)
# 4. 16 → 8:  kernel=3, stride=2, RF=3×3 (9.50M params)
compression:
  input_grid_size: 24   # Input token grid size: 16 or 24
  output_grid_size: 8   # Output token grid size: 8 or 12

# Data settings
data:
  imagenet_root: "/home/elicer/ImageNet"  # UPDATE THIS PATH
  num_workers: 4
  pin_memory: true
  use_subset: false  # Set to true for quick testing
  subset_size: 1000

# Hardware settings
hardware:
  cuda_device: 0  # CUDA device number
  mixed_precision: true  # Use automatic mixed precision for 1.5-2x speedup
  compile: false  # Use torch.compile (requires PyTorch 2.0+)

# Checkpoint settings
checkpoint:
  save_dir: "./checkpoints_rf"  # Will be auto-suffixed with config (e.g., checkpoints_rf/24to8)
  save_frequency: 5  # Save every N epochs
  keep_last_n: 3  # Keep only last N checkpoints

# Validation settings
validation:
  frequency: 1  # Validate every N epochs
  save_rf_visualizations: true  # Save RF reconstruction visualizations
  visualize_rf_indices: [0, 17, 35]  # Which RFs to visualize (adjust based on output_grid_size^2)
  compute_detailed_stats: true  # Compute per-RF statistics

# Logging settings
logging:
  log_frequency: 50  # Log to wandb every N steps
  print_frequency: 10  # Print to console every N steps
